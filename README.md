# Climate Vulnerability

## Abstract
This project aims to determine counties in the United States that are both the most vulnerable to climate change and the least likely to have funding to address such vulnerability. Should there be funding available for remediating climate vulnerability (e.g. from the federal government), then these counties should be prioritized.

## Method
For this analysis, climate vulnerability data was gathered for four different types of climate risks: flooding, wildfires, extreme heat, and wind hazards. Funding data was gathered as county government expenditure data. These two sets of data were then combined to determine the counties that had the highest climate vulnerability and the lowest government expenditure as the final output of the analysis.

## Inputs

Climate Vulnerability Data:  There are four CSV files that need to be gathered from the First Street Foundation. Their public data is obtained through [AWS Marketplace](https://aws.amazon.com/marketplace/seller-profile?id=b777a8d0-ad41-4190-b94a-27e18e87e17f). This analysis will require Flood Factor, Heat Factor, Fire Factor, and Wind Factor data through AWS. The zip files for each risk factor type will contain data for different levels of aggregation. This analysis will specifically require the **county** level data. The files should be named the following:
+ fsf_flood_county_summary.csv
+ fsf_fire_county_summary.csv
+ fsf_heat_county_summary.csv
+ fsf_wind_county_summary.csv

Risk Factor is a tool developed by the First Street Foundation that allows users to view the level of risk that a specific property has for different types of climate hazards. Properties are given a score from 1-10 for each type of climate risk, 1 being low to minimal risk and 10 being the highest risk. The CSV files aggregate the number of properties for each score for at the county level. For example, a county may have 10 properties with a Flood Risk score of 2 and 500 properties with a Flood Risk score of 4. For more information on Risk Factor and its risk scoring system visit the [Risk Factor website](https://riskfactor.com/).
<br/><br/>
County Expenditure Data: There is one CSV that needs to be downloaded from The Government Finance Database on Williamette University's website. Vist the [webpage](https://willamette.edu/mba/research-impact/public-datasets/index.html) and click the link labelled "Download only the county government data". Alternatively click on this link [here](https://willamette.edu/~kpierson/TheGovernmentFinanceDatabase_CountyData.zip) for a direct download. The relevant file within the zip should be named the following:
+ CountyData.csv

The Government Finance Database attempts to compile and aggregate all the publicly available data gathered by the U.S. Census Bureau on state and local government expenditures. The U.S. Census Bureau has only released such data aggregated to the state level since 2012. To gather county level data, the Government Finance Database is the most coherent source in aggregating the Census data. For more information, visit their [webpage](https://willamette.edu/mba/research-impact/public-datasets/index.html).

The repository contains the First Street data inputs in the subdirectory /inputs/ as of 2023 but for the most up to date data and to give credit to the original sources, please use these directions to obtain the data.

## Scripts
Once the inputs have been gathered, the python scripts in the repository should be ran in the following order:
1. risk.py
1. expenditures.py
1. vulnerabilities_assistance.py

The following scripts are optional to be run but supplemental:
1. fsf_renaming.py
1. risk_score_distributions.py

fsf_renaming.py: This script defines a function that can read the CSV files of county level risk factor data and then rename the risk score columns to be simple digits. This makes the data easier to use. It is referenced as a module in 'risk.py' and 'risk_score_distributions.py' and so it is not necessary to run.

risk.py: This script reads the risk factor CSV files and calculates the **% of properties that are "at risk"** for every county and categorizes a county's **risk level** based on this %. A property is counted as "at risk" if they had a risk score above a certain cutoff. This cutoff score was determined in 'risk_score_distributions.py'. The output of this script is four CSV files corresponding to each risk factor that are used in 'vulnerabilities_assistance.py'. They have the following name format "{risk type}_risk.csv'.

risk_score_distributions: This script determines the risk score cutoffs for the calculations in 'risk.py'. It also visualizes the property counts or distribution of every risk score for different sets of aggregations. This script is not necessary for the main analysis, but will produce a total of 16 graph PNGs, 4 for each risk type. To be run, it has to be run after 'risk.py'.

expenditures.py: This script reads the county expenditure data and calculates the **per capita expenditure** for every county with data available for 2020. The script then categorizes a county's **expenditure level** based on the its percentile rank in relation to per capita expenditure. The output of this script is a CSV file named 'expenditures.csv' and is used in 'vulnerabilities_assistance.py'.

vulnerabilities_assistance.py: The script reads in the four CSVs of risk data and the one CSV of expenditure data previously created. The script then filters down to the **most vulnerable** counties for each risk type. Then using this subset, the most vulnerable counties without expenditure data were found and the most vulnerable counties with the lowest expenditure levels were found. The former subset were outputted as 4 CSVs with the format, '{risk type}_vulnerable_missing.csv'. The latter subset contains the main findings of this analysis and were outputted as 4 CSVs with the format, '{risk}_assistance.csv' to denote the counties that should be targetted for financial assistance.

## Outputs
The main scripts should produce the following outputs in this order:
1. flood_risk.csv, fire_risk.csv, heat_risk.csv, wind_risk.csv:
<br/>

2. expenditures.csv
3. flood_vulnerable_missing.csv, fire_vulnerable_missing.csv, heat_vulnerable_missing.csv, wind_vulnerable_missing.csv
4. flood_assistance.csv, fire_assistance.csv, heat_assistance.csv, wind_assistance.csv

## Results
The purpose of this analysis was to create a list of counties that should be targetted for financial assistance. However, the only lists created that were practical were for flood assistance and wildfire assistance, with 7 counties and 26 counties listed respectively. The lists for heat and wind assistance had well over 100 counties, despite adjustments in the scripts to limit the criteria and create a smaller list. Futher criteria limitations should be set to produce smaller lists. Additionally, overlapping these lists could produce smaller lists and create targets of general assistance rather than assistance for one type of climate risk. Nevertheless, the current list of counties found in 'flood_assistance.csv' and 'fire_assistance.csv' are counties that should be targetting for financial assistance with climate vulnerability.









